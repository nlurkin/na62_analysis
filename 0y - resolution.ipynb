{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d8033a-4721-4469-b6cf-c6f8d6c07bc4",
   "metadata": {},
   "source": [
    "# Detector resolution\n",
    "As you know, detectors are not perfect and do not provide an infinitely precise measurement. Instead they have resolutions that may be a constant value, or may depend on the measured value itself.\n",
    "In this notebook we will explore the energy resolution of the LKr detector, and the time and momentum resolution of the Spectrometer.\n",
    "\n",
    "The resolution is the difference that we may find between the measured value and a reference value (the \"real\" value). Unless working with simulation, we usually cannot know the exact real value. So we need to find either a reference value which was measured with a resolution that was much smaller than the resolution that we are trying to measure. This would give us an \"exact\" value for all practical purposes. Alternatively we can measure the resolution with respect to another measurement for which the resolution is already well known, or with respect to another measurement provided by the same detector (if this is practical). For these two last cases, the measured resolution will be the convolution of both measurements but the resolution of the tested detector can be obtained by deconvolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b621d-f4d1-4daf-946d-d584eebc7c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual let's import all we need\n",
    "import uproot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from na62 import prepare, hlf, extract, constants, stats\n",
    "from lmfit import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ec178-c6cb-4c49-b233-fefdc78c95a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we load the data\n",
    "data, _ = prepare.import_root_files([\"data/run12450.root\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103bb19-828f-4a4f-90d1-04a1931443f1",
   "metadata": {},
   "source": [
    "# LKr energy resolution\n",
    "To measure the LKr energy resolution we can use one of the principles that we have seen in the PID notebook. We know that in almost 100% of the cases, electrons will leave all their energy inside the LKr. As a consequence if we can isolate a pure sample of electrons and knowing their energy (momenta), we have a reference for the energy that is supposed to be measured in the LKr. This can easily be provided by the Ke3 decay.\n",
    "\n",
    "Let's first isolate a sample of Ke3, similarly to what we did in the PID notebook. However to improve the efficiency of our selection and increase both the statistics and the purity, we are not going to reject events that are in the $m_\\text{miss}^2(\\mu)$ peak (i.e. assuming muon mass for the track) but instead reject events where the track is associated to a MUV3 signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04b68d-a2aa-44a2-b0de-20937b30b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our momentum and missing mass squared peaks parameters, as in the PID notebook\n",
    "p_center = 75000\n",
    "p_sigma = 1100\n",
    "mm2_mean = 0\n",
    "mm2_sigma = 3000\n",
    "\n",
    "# --- Define the selection cuts we will need ---\n",
    "# Event topology\n",
    "single_track_w_clusters_cond = hlf.make_exists_cut([\"track1_exists\", \"cluster1_exists\", \"cluster2_exists\"], [\"track2_exists\", \"track3_exists\"])\n",
    "# Total momentum\n",
    "ptot_condition = hlf.n(hlf.make_total_momentum_cut((p_center-5*p_sigma), (p_center+5*p_sigma)))\n",
    "# Missing mass squared\n",
    "in_ke3_peak_cond = hlf.make_missing_mass_sqr_cut((mm2_mean-3*mm2_sigma), mm2_mean+3*mm2_sigma, {\"track1\": constants.electron_mass, \"cluster1\": constants.photon_mass, \"cluster2\": constants.photon_mass})\n",
    "# MUV3 signal\n",
    "muv3_notmu_cond = hlf.make_muv3_cut(False, \"track1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971bbe13-ae4c-40a3-a17e-49f8f91ef4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cuts to the data\n",
    "ke3_events = hlf.select(data, [single_track_w_clusters_cond, ptot_condition, in_ke3_peak_cond, muv3_notmu_cond])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9921a-b305-4050-87b5-b070d244be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add here selection quality plots for confirmation with MC. Use techniques from 04\n",
    "# Find out which channel polutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e67af4-1b8b-4262-b948-80b4e1de40c3",
   "metadata": {},
   "source": [
    "Let's have a look at the E/p distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f72a1-0ee3-4a5f-a26c-b750746d3548",
   "metadata": {},
   "outputs": [],
   "source": [
    "ke3_events[\"track1_eop\"].hist(bins=100)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"E/p\")\n",
    "plt.title(\"E/p distribution for Ke3 candidates sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df7a571-be2e-4616-b658-7429da394f47",
   "metadata": {},
   "source": [
    "We can see that we do have some polution from another channel. However the electron peak is very clear and enough for our purpose. We want to fit the resolution for the tracks that are in the peak around 1. We can simply reject events with $E/p<0.8$ as those are clearly not electrons having been entirely absorbed inside the LKr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50427d-1ed2-44c2-a055-b8f1a9f5c917",
   "metadata": {},
   "outputs": [],
   "source": [
    "eop_condition = hlf.make_eop_cut(0.8, None, \"track1\")\n",
    "ke3_events = hlf.select(ke3_events, [eop_condition])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ded594-29bc-4a37-bf4c-07e5c8cb1a0a",
   "metadata": {},
   "source": [
    "Let's now extract the expected track energy using the measured momentum, and compute the difference with respect to the measured energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c7a34-2a7a-4632-ae12-5e8427cc9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = extract.track(ke3_events, 1)\n",
    "e_energy = np.sqrt(e[\"momentum_mag\"]**2 + constants.electron_mass**2)\n",
    "delta_e = e[\"lkr_energy\"] - e_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a73ff0f-4070-4cd5-a4fd-45ed45b33215",
   "metadata": {},
   "source": [
    "We can now plot and fit this difference. We will try to fit with a Gaussian model, and also with a double Gaussian model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f42375-5b63-4738-8a21-446d8552fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a figure\n",
    "ax = plt.figure().gca()\n",
    "\n",
    "gauss_fit = stats.perform_fit(delta_e, bins=100, display_range=(-6000, 6000), ax=ax, model_wrapper=stats.gaussian_wrapper, fit_label=\"Single Gaussian\")\n",
    "gauss2_fit = stats.perform_fit(delta_e, bins=100, display_range=(-6000, 6000), ax=ax, model_wrapper=stats.gaussian2_wrapper, fit_label=\"Double Gaussian\")\n",
    "plt.xlabel(\"$\\Delta E$ [MeV]\")\n",
    "plt.title(r\"$\\Delta E = E_\\mathrm{LKr} - E_\\mathrm{Straw}$ for electron sample\")\n",
    "print(f\"Single Gaussian reduced Chi2: {gauss_fit.redchi:.2f}\")\n",
    "print(f\"Double Gaussian reduced Chi2: {gauss2_fit.redchi:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92aedce-f61a-4ec5-92e5-b82979d65f54",
   "metadata": {},
   "source": [
    "We can see in this case that the double Gaussian looks much better, both visually and comparing the reduced Chi2. We are therefore going to use the result of the double Gaussian model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659a8d83-c28f-49e0-8007-eed34f97ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss2_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d3d627-82c0-4337-975c-42255dbdfefd",
   "metadata": {},
   "source": [
    "We can conclude two things from this fit result:\n",
    " - The mean of both Gaussians are slightly but significantly shifted to negative value. This means that the measured energy is always a little less than what we can expect from the momentum measurement (but we cannot tell from this only which one, if any, is more correct).\n",
    " - The energy resolution, measured using the $\\sigma$ of the dominating Gaussian is around $\\sigma_{\\Delta E} \\sim 327 \\pm 6$ MeV.\n",
    "\n",
    "However we have to keep in mind that this resolution is the convolution of the LKr energy resolution and the Spectrometer momentum resolution.\n",
    "$$\\Delta E = E_\\text{LKr} - E_\\text{Straw}$$\n",
    "$$\\sigma_{\\Delta E} = \\sqrt{\\sigma_{E_\\text{LKr}}^2 + \\sigma_{E_\\text{Straw}}^2} \\sim 327 \\pm 6~\\text{MeV}$$\n",
    "We will however assume in the following that the Straw resolution is *small* with respect to the LKr resolution and can therefore be neglected at first order.\n",
    "\n",
    "We also know that the resolution on the energy is not constant and depends on the energy itself. So we can select ranges of energy, repeat this procedure and extract the sigma for each range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c336fa2d-a67c-402c-b4b5-4bc88090e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin the energies between 0 and 80 GeV in bins of 5 GeV\n",
    "bin_size = 5000\n",
    "cut = pd.cut(e_energy, np.arange(0,80000, bin_size), labels=False)\n",
    "\n",
    "# Prepare arrays to store the fit results (bin center, sigma, fit error on sigma)\n",
    "energy = []\n",
    "values = []\n",
    "err = []\n",
    "\n",
    "# Loop over the bins in increasing order\n",
    "for binID in cut.value_counts().sort_index().index:\n",
    "    # Select only the tracks in the current bin\n",
    "    delta_e_bin = delta_e.loc[cut==binID]\n",
    "\n",
    "    # Remove bins containing too little stat (request at least 100 tracks in the bin)\n",
    "    if(len(delta_e_bin)<=100):\n",
    "        continue\n",
    "\n",
    "    # Perform the fit, using the double Gaussian model\n",
    "    fitr = stats.perform_fit(delta_e_bin, bins=100, display_range=(-6000, 6000), model_wrapper=stats.gaussian2_wrapper)\n",
    "\n",
    "    # Fill the arrays with the results\n",
    "    energy_val = binID*bin_size + bin_size/2.\n",
    "    energy.append(energy_val)\n",
    "    values.append(fitr.params[\"sigma\"].value)\n",
    "    err.append(fitr.params[\"sigma\"].stderr)\n",
    "\n",
    "# Transform the result arrays into numpy array for easier processing later\n",
    "energy = np.array(energy)\n",
    "values = np.array(values)\n",
    "err = np.array(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b77c67-806f-4ed4-a25b-cfe494420f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relative resolution (sigma/E)\n",
    "plt.errorbar(energy, values/energy, yerr=err/energy, capsize=2)\n",
    "plt.title(\"Convoluted LKr $\\oplus$ Straw energy resolution as a function of the energy\")\n",
    "plt.ylabel(\"$\\sigma_E/E$\")\n",
    "plt.xlabel(\"E [MeV]\")\n",
    "plt.grid(\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f276bf37-037b-4e67-ab95-02a119fb3ea7",
   "metadata": {},
   "source": [
    "The curve above corresponds to the relative resolution $\\frac{\\sigma_E}{E}$. This can be parametrized as $\\frac{\\sigma_E}{E} = a \\oplus \\frac{b}{\\sqrt{E}} \\oplus \\frac{c}{E} = a \\oplus bE^{-1/2} \\oplus cE^{-1}$ (with E in GeV to be able to compare with the official model). Let's fit the curve with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63a2a0-7dbe-481f-a8c3-146c29442479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model \n",
    "def lkr_resolution_model(E, a, b, c):\n",
    "    E = E/1000 # E in GeV for the model\n",
    "    return np.sqrt(a**2 + (b/np.sqrt(E))**2 + (c/E)**2)\n",
    "\n",
    "# Create the lmfit model\n",
    "model = Model(lkr_resolution_model)\n",
    "# Initial guess for the parameters (not unreasonable)\n",
    "params = model.make_params(a = 0.01, b=0.01, c=0.01)\n",
    "\n",
    "# Perform the fit\n",
    "result = model.fit(values/energy, params, E=energy, weights=1/(err/energy))\n",
    "\n",
    "# Plot the result\n",
    "plt.errorbar(energy, values/energy, yerr=err/energy, capsize=2, label=\"Measured resolution\")\n",
    "plt.plot(energy, result.best_fit, '-', label='best fit')\n",
    "plt.plot(energy, lkr_resolution_model(energy, 0.009, 0.048, 0.11), ':', label='Official resolution model')\n",
    "plt.legend()\n",
    "plt.title(\"Convoluted LKr $\\oplus$ Straw energy resolution as a function of the energy\")\n",
    "plt.ylabel(\"$\\sigma_E/E$\")\n",
    "plt.xlabel(\"E [MeV]\")\n",
    "plt.grid(\"both\")\n",
    "\n",
    "# Print the fit result\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019fd264-a8ce-4887-9697-842c64e63eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"a = {result.params['a'].value:.1%} +- {result.params['a'].stderr:.1%}\")\n",
    "print(f\"b = {result.params['b'].value:.1%} +- {result.params['b'].stderr:.1%}\")\n",
    "print(f\"c = {result.params['c'].value:.1%} +- {result.params['c'].stderr:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9a775-6ee8-4b03-9ef4-a91c334960b9",
   "metadata": {},
   "source": [
    "The officially recognized resolution is \n",
    "$$\\frac{\\sigma_E}{E} = 0.9\\% \\oplus \\frac{4.8\\%}{\\sqrt{E}} \\oplus \\frac{11\\%}{E}$$\n",
    "while our measurement provides:\n",
    "$$\\frac{\\sigma_E}{E} = 0.6\\% \\oplus \\frac{6.1\\%}{\\sqrt{E}} \\oplus \\frac{11.7\\%}{E}$$\n",
    "\n",
    "This result is not too bad, parameters 'a' and 'c' are very close to their official value and 'b' is only a couple of percents away (but within uncertainties)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81c779-11f5-42aa-8853-3e12d5804b00",
   "metadata": {},
   "source": [
    "# Spectrometer momentum resolution\n",
    "\n",
    "## Using data\n",
    "To measure the momentum resolution of the Spectrometer, we can use closed kinematics events involving tracks only (K3pi). In this way, we can select one of the tracks and reconstruct it from the rest of the event (the beam momentum and the two other tracks) to give us the expected momentum. This can then be compared with the measured momentum of the track. The resolution on this difference is a convolution of three times the Spectrometer momentum resolution (once for each track) and the beam momentum resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1eb3d9-af8d-47d8-b4f3-e976ce042ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our momentum and missing mass squared peaks parameters, as in the PID notebook\n",
    "m_center = constants.kaon_charged_mass\n",
    "m_sigma = 1\n",
    "\n",
    "# --- Define the selection cuts we will need ---\n",
    "# Event topology\n",
    "three_tracks_cond = hlf.make_exists_cut([\"track1_exists\", \"track2_exists\", \"track3_exists\"], [\"cluster1_exists\", \"cluster2_exists\"])\n",
    "# Invariant mass\n",
    "ptot_condition = hlf.make_invariant_mass_cut((m_center-5*m_sigma), (m_center+5*m_sigma), mass_assignments={\"track1\": constants.pion_charged_mass, \"track2\": constants.pion_charged_mass, \"track3\": constants.pion_charged_mass})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5430610-9873-46b4-b7c2-a39d49ece93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k3pi = hlf.select(data, [three_tracks_cond, ptot_condition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f163fac-02d5-45c1-95bf-93fc4843621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract negative tracks and positive tracks\n",
    "# Positive will be pos1 and pos2, arbitrarily, doesn't matter\n",
    "\n",
    "# Extract tracks\n",
    "t1 = hlf.set_mass(extract.track(k3pi, 1), constants.pion_charged_mass)\n",
    "t2 = hlf.set_mass(extract.track(k3pi, 2), constants.pion_charged_mass)\n",
    "t3 = hlf.set_mass(extract.track(k3pi, 3), constants.pion_charged_mass)\n",
    "\n",
    "# Extract negatives from t1, t2, t3 and store the corresponding 2 positive tracks in their respective arrays.\n",
    "# Then rotate and do it again (this is only to put that in a loop and avoid 3 repetitions of the code\n",
    "# Need to do beam at the same time to take care of index misalignment\n",
    "t_neg_arr = []\n",
    "t_pos1_arr = []\n",
    "t_pos2_arr = []\n",
    "beam_arr = []\n",
    "beam = extract.get_beam(k3pi)\n",
    "t = [t1, t2, t3]\n",
    "for i in range(3):\n",
    "    neg_tracks = t[0][\"charge\"]==-1\n",
    "    t_neg = t[0].loc[neg_tracks]\n",
    "    t_pos1 = t[1].loc[neg_tracks]\n",
    "    t_pos2 = t[2].loc[neg_tracks]\n",
    "    t_neg_arr.append(t_neg)\n",
    "    t_pos1_arr.append(t_pos1)\n",
    "    t_pos2_arr.append(t_pos2)\n",
    "    beam_arr.append(beam.loc[neg_tracks])\n",
    "    t = [t[1], t[2], t[0]]\n",
    "\n",
    "# Merge the dataframes in the arrays\n",
    "t_neg = pd.concat(t_neg_arr)#.reset_index()\n",
    "t_pos1 = pd.concat(t_pos1_arr)#.reset_index()\n",
    "t_pos2 = pd.concat(t_pos2_arr)#.reset_index()\n",
    "beam = pd.concat(beam_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b1847-da16-444a-8708-5ef7f7fd652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will choose t_pos2 as the tested track because we want to test performances on a positive track. Which one doesn't matter\n",
    "expected = hlf.three_vectors_sum([beam, hlf.three_vector_invert(t_neg), hlf.three_vector_invert(t_pos1)])\n",
    "# And compute the delta between the expected and measured value\n",
    "delta_p = expected[\"momentum_mag\"] - t_pos2[\"momentum_mag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd70ee-6bd1-479a-b26a-46036523065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss2_fit = stats.perform_fit(delta_p, bins=100, display_range=(-5000, 5000), fit_range=(-2000, 2000), plot=True, model_wrapper=stats.gaussian_wrapper, fit_label=\"Double Gaussian\")\n",
    "plt.xlabel(\"$\\Delta p$ [MeV]\")\n",
    "plt.title(r\"$\\Delta p = p_\\mathrm{K3pi} - p_\\mathrm{Straw}$ for K3pi sample\")\n",
    "#plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8336eef-2440-413d-82d3-c7b9e08b2145",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss2_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1368e-d29e-46ba-93f0-19daa328579f",
   "metadata": {},
   "source": [
    "Fit result is ~1000 MeV but this is $\\sigma^2 = \\sigma^2_{t1} + \\sigma^2_{t2} + \\sigma^2_{t3} + \\sigma^2_\\mathrm{Beam} \\approx 3\\sigma^2_\\mathrm{Straw} + \\sigma^2_\\mathrm{Beam}$\n",
    "If we want the Straw resolution, we would have to take into account the Beam resolution:\n",
    "$$\\sigma_\\mathrm{Straw} = \\sqrt{\\frac{\\sigma^2 - \\sigma^2_\\mathrm{Beam}}{3}}$$\n",
    "\n",
    "However the beam resolution is not known and can be quite large as it is only statistically measured over time. Let's make an exercise:  \n",
    "Starting from the measured resolution from the fit above, let's apply the formula and estimate the 'true' Straw single track resolution as a function of the beam resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b19a2b-8887-4167-a07f-0967c6b92c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the measured resolution\n",
    "measured_sigma = gauss2_fit.params[\"sigma\"].value\n",
    "\n",
    "# Generate beam resolution from 0 to the measured resolution (cannot be higher, else the measured resolution would be higher)\n",
    "beam_res = np.arange(0,measured_sigma)\n",
    "\n",
    "# Compute the estimated Straw single track resolution using the formula and plot it\n",
    "sigma_straw = np.sqrt((gauss2_fit.params[\"sigma\"].value**2 - beam_res**2)/3)\n",
    "plt.plot(beam_res, sigma_straw)\n",
    "plt.grid(\"both\")\n",
    "plt.title(\"Estimated Straw single track resolution vs beam resolution\")\n",
    "plt.xlabel(\"$\\sigma_\\mathrm{Beam}$ [MeV]\")\n",
    "plt.ylabel(\"$\\sigma_\\mathrm{Straw}$ [MeV]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3f36d-82d7-410c-81af-a53d5721f2ea",
   "metadata": {},
   "source": [
    "We see that depending on the beam resolution we can actually estimate any Straw momentum resolution between ~550 MeV and 0 MeV.\n",
    "\n",
    "Similarly to the LKr case, we can again compute the resolution in momentum bins. Doing this, we will record both the \"raw\" resolution (the sigma of $p_\\text{exp}-p_\\text{meas}$) but also the Straw \"single-track resolution\" using one of the most extreme case above where the raw resolution would be almost entirely due to the beam resolution ($\\sigma_\\text{Beam} = 870$ MeV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd39a681-63f1-4ea7-88ee-9f37046dd44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin the momentum between 0 and 80 GeV in bins of 5 GeV\n",
    "bin_size = 5000\n",
    "cut = pd.cut(expected[\"momentum_mag\"], np.arange(0,80000, bin_size), labels=False)\n",
    "\n",
    "# Prepare arrays to store the fit results (bin center, sigma, sigma_single_track, fit error on sigma)\n",
    "momentum = []\n",
    "values = []\n",
    "values_single = []\n",
    "err = []\n",
    "\n",
    "# Loop over the bins in increasing order\n",
    "for binID in cut.value_counts().sort_index().index:\n",
    "    # Select only the tracks in the current bin\n",
    "    dp = delta_p.loc[cut==binID]\n",
    "\n",
    "    # Remove bins containing too little stat (request at least 100 tracks in the bin)\n",
    "    if(len(dp)<=100):\n",
    "        continue\n",
    "\n",
    "    # Perform the fit, using the single Gaussian model\n",
    "    fitr = stats.perform_fit(dp, bins=100, display_range=(-3000, 3000))\n",
    "\n",
    "    # Extract the single track sigma and fill the arrays with the results\n",
    "    p = binID*bin_size + bin_size/2.\n",
    "    momentum.append(p)\n",
    "    sigma = fitr.params[\"sigma\"].value\n",
    "    sigma_beam = 870\n",
    "    sigma_single = np.sqrt((sigma**2 - sigma_beam**2)/3)\n",
    "    values.append(sigma)\n",
    "    values_single.append(sigma_single)\n",
    "    err.append(fitr.params[\"sigma\"].stderr)\n",
    "\n",
    "# Transform the result arrays into numpy array for easier processing later\n",
    "momentum = np.array(momentum)\n",
    "values = np.array(values)\n",
    "values_single = np.array(values_single)\n",
    "err = np.array(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e8205-7ca8-475e-aa00-1183dfa2a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the relative resolution (sigma/E) for the fitted sigma (raw) and the single track sigma (computed)\n",
    "plt.errorbar(momentum, values/momentum, yerr=err/momentum, capsize=2, label=\"Raw resolution ($P_\\mathrm{exp} - P_\\mathrm{meas}$)\")\n",
    "plt.errorbar(momentum, values_single/momentum, yerr=err/momentum, capsize=2, label=\"Single track resolution\")\n",
    "plt.legend()\n",
    "plt.title(\"Extracted resolution of the Straw track in bins of momentum\")\n",
    "plt.xlabel(\"p [MeV]\")\n",
    "plt.ylabel(\"$\\sigma_p$\")\n",
    "plt.grid(\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c83b980-fc07-4fcc-a300-d95976ac36a5",
   "metadata": {},
   "source": [
    "The curve above corresponds to the relative resolution $\\frac{\\sigma_p}{p}$. This can be parametrized as $\\frac{\\sigma_p}{p} = a \\oplus bp$ (with $p$ in GeV to be able to compare with the official model). Let's fit the curve with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a851d412-c635-448c-8adc-268f03138b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model \n",
    "def straw_resolution_model(P, a, b):\n",
    "    P = P/1000 # P in GeV for the model\n",
    "    return np.sqrt(a**2 + (b*P)**2)\n",
    "\n",
    "# Create the lmfit model\n",
    "model = Model(straw_resolution_model)\n",
    "# Initial guess for the parameters (not unreasonable)\n",
    "params = model.make_params(a = 0.01, b=0.001)\n",
    "\n",
    "# Perform the fit\n",
    "result = model.fit(values_single/momentum, params, P=momentum, weights=1/(err/momentum))\n",
    "\n",
    "# Plot the result\n",
    "plt.errorbar(momentum, values_single/momentum, yerr=err/momentum, capsize=2, label=\"Measured resolution\")\n",
    "plt.plot(momentum, result.best_fit, '-', label='best fit')\n",
    "plt.plot(momentum, straw_resolution_model(momentum, 0.003, 0.00005), ':', label='Official resolution model')\n",
    "plt.legend()\n",
    "plt.title(\"Extracted Straw momentum resolution as a function of the momentum\")\n",
    "plt.ylabel(\"$\\sigma_p/p$\")\n",
    "plt.xlabel(\"p [MeV]\")\n",
    "plt.grid(\"both\")\n",
    "\n",
    "# Print the fit result\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d65d7f-2a63-43e1-ae73-2fbc1c1f86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"a = {result.params['a'].value:.1%} +- {result.params['a'].stderr:.1%}\")\n",
    "print(f\"b = {result.params['b'].value:.1%} +- {result.params['b'].stderr:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524a0571-6f8a-4a85-a720-15cb63321993",
   "metadata": {},
   "source": [
    "The officially recognized resolution is \n",
    "$$\\frac{\\sigma_p}{p} = 0.3\\% \\oplus 0.005\\%p$$\n",
    "while our measurement provides:\n",
    "$$\\frac{\\sigma_p}{p} = 0.5\\% \\oplus 0.0\\%p$$\n",
    "\n",
    "From the two plots above, it is very clear that the measured \"raw\" resolution is very far away from the official value. The functional shape of the curve is not even similar. This means that our measurement didn't work at all and is indeed dominated by the resolution on the reference value (i.e. probably the beam component). Taking into account a very high beam resolution, we reach something closer to the official value (parameter 'a' is only a fraction of percent away from the real value, but 'b' cannot be measured). Given the measurement shown on the plot above, it is however very doubtful that we can actually measure anything meaningful in this way.\n",
    "\n",
    "We can use a different technique to extract the resolution from Monte-Carlo simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce7af3-ca5a-44a1-92fe-021e3aef4cd5",
   "metadata": {},
   "source": [
    "# From Simulation\n",
    "Instead we are now going to use simulated data and use as reference the exact real momentum that was input in the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb4d91-7858-4028-b25a-a4a6cb3a0de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
