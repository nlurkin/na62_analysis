{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f796c064-799b-4c34-863a-5b73292074a7",
   "metadata": {},
   "outputs": [],
  {
   "cell_type": "markdown",
   "id": "51a65293-62d9-4a0a-8dda-1f030c2626ef",
   "metadata": {},
   "source": [
    "# Timing\n",
    "\n",
    "Timing in an experiment like NA62 is very different from other experiment such as LHC. For LHC experiments, the timing of the events is very well knows: one event comes every 25 ns. In NA62 we have a continuous beam of particle coming over periods of ~4.5 s (that we call burst or spill). During the burst we have about 750 MHz of particles entering the detector. Out of these, 6% are Kaons and only a fraction of them will decay in the fiducial decay volume. This means that every burst will see millions of Kaon decays and timing is therefore extremely important to be able to separate them. Different detectors will see different particle rates, but it is important to be able to consistently associate signals in time across all detectors, and therefore they should all have at least a resolution of the same order of magnitude. In the case of NA62, all detectors have a time resolution of better than ~1 ns.\n",
    "\n",
    "The timing intervenes at multiple levels in NA62. The first level is the trigger. A clock signal is is distributed through the whole experiment with a period of approximately 25 ns (exactly: 24.951059536 ns). This period defines what we call a \"frame\" and it is used as a reference for the generated triggers. Once a trigger is generated and distributed to all detectors, they will send all the signals they acquired in the reference frame (and a couple of frames on either side to ensure we have all we need before throwing it away). After further processing the data are written on disk. This trigger period, or frame, therefore defines the time window of each event. Within this time window, each detector has a faster clock defining a finer time (generally of the order of few 100 of ps). This fine time is the one that we will really use to associate in time signals in different detectors.\n",
    "\n",
    "In this notebook we will investigate timing consideration. We have a few time variables in our data format and will we check how they correlate and how we can use it to remove spurious associations and reduce random veto (rejecting an event based on detector activity unrelated to the event of interest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e1f0d-c948-4b1d-b503-d9eaa8a54637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual let's import all we need\n",
    "import uproot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from na62 import prepare, hlf, extract, constants, stats\n",
    "from lmfit import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dbe2f7-dbce-4ebb-a6cb-d8046c7efc09",
   "metadata": {},
   "source": [
    "**Exercise**: Knowing that Kaons in NA62 have energy of 75 GeV, what fraction of them will decay in the 80 m decay volume? How many decays is that over the 3 s period of a burst?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e69d54-77ee-4150-9c73-36e07c9265ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the fraction of Kaon decaying in the decay volume\n",
    "p = 75000 # MeV\n",
    "E = np.sqrt(p**2+constants.kaon_charged_mass**2) \n",
    "tau = 1.2380e-8 # Kaon lifetime\n",
    "gamma = E/constants.kaon_charged_mass\n",
    "length = 80\n",
    "beam_rate = 750 # MHz\n",
    "kaon_fraction = 0.06\n",
    "burst_length = 3 # s\n",
    "\n",
    "meanpath = constants.c*gamma*tau\n",
    "# Which fraction will decay in the decay volume = decay probability in the given length\n",
    "prob = 1 - np.exp(-length/meanpath)\n",
    "decay_rate = beam_rate*1e6 * kaon_fraction * prob \n",
    "ndecays = decay_rate * burst_length\n",
    "\n",
    "print(f\"Kaon mean free path: {meanpath:.0f} m\")\n",
    "print(f\"Probability of kaon decay within {length} m distance: {prob:.2%}\")\n",
    "print(f\"Number of decays in the burst: {ndecays:.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f79bcd-fef8-4b01-aa5d-285e48979465",
   "metadata": {},
   "source": [
    "**Exercise**: What is the maximum time resolution should we achieve to be able to distinguish individual events? Check the ideal case where the detector is sensitive to Kaon decays only. But some of the detectors are actually sensitive also to the full beam, which is the maximum time resolution in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31063da1-e0a0-4b4c-a5b6-ebc5c76c0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The required time resolution to distinguish between two events is simply the time between two events\n",
    "time_between_kaons = 1/decay_rate * 1e9 # In ns\n",
    "time_between_beam = 1/(beam_rate * 1e6) * 1e9 # Beam rate in Hertz, then transform into ns\n",
    "\n",
    "print(f\"Average time between consecutive kaon decays: {time_between_kaons:.2f} ns\")\n",
    "print(f\"Average time between consecutive beam particles: {time_between_beam:.2f} ns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bec9e9-6489-4208-8e74-70abcb927e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read the data as usual\n",
    "data, _ = prepare.import_root_files([\"data/run12450.root\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba69220-480a-4767-a68e-aec1256ad991",
   "metadata": {},
   "source": [
    "## Track - MUV3 timing\n",
    "Let's first investigate the relationship between our track and the MUV3 signal. As you know, each track has a boolean variable indicating whether the track has MUV3 signal associated. However this association is spatial only, the timing is not considered. This means that a perfectly valid electron track may have a MUV3 (muon) signal associated. We know this is extremely unlikely that the electron itself leaves any signal on the MUV3. This situation can happen if a muon coming from the beam line hits the MUV3 at the same place as the electron would when we extrapolate its position on the MUV3. Given the rate of muons coming from the beam line, this situation is actually not unlikely. \n",
    "\n",
    "Let's take all the tracks that have MUV3 signal and look at the time difference between the track time and the MUV3 time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc4bd9-a4b1-422d-92bd-8c1c5eda9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all tracks with MUV3\n",
    "all_tracks = extract.all_tracks(data)\n",
    "all_tracks = all_tracks.loc[all_tracks[\"has_muv3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f7dad-4745-49dc-848f-03fa403f6143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And plot the time difference\n",
    "(all_tracks[\"muv3_time\"]-all_tracks[\"time\"]).hist(bins=250, range=(-100, 150))\n",
    "plt.title(\"Time difference between track and associated MUV3 signal\")\n",
    "plt.xlabel(\"$\\Delta t$ [ns]\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0f6bba-1c18-4a85-99e5-917439159cc4",
   "metadata": {},
   "source": [
    "This plot clearly shows a very large peak which corresponds to tracks where the MUV3 signal is related to the track. The width of this peak is related to the time resolution of the track and the MUV3. We have at a lower level, a flatish distribution of random association.  \n",
    "We are now going to define an in-time MUV3 signal based on the resolution of this peak. Let's measure it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f3ea0-ef96-40f6-98b1-d866fa33c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stats.perform_fit(all_tracks[\"muv3_time\"]-all_tracks[\"time\"], bins=100, display_range=(-20, 20), fit_range=(-10, 10), plot=True, model_wrapper=stats.gaussian2_uniform_wrapper)\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(bottom=0.8)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e04ea4-2594-4150-8736-5fe331a7e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Measured time resolution: {result.params['m0_sigma'].value*1e3:.0f} +- {result.params['m0_sigma'].stderr*1e3:.0f} ps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc6f08-339b-406b-9d76-596981167935",
   "metadata": {},
   "source": [
    "From this we conclude that we have a time resolution of about 400 ps on the the MUV3 association with a track. To make sure we catch most associations correctly, we are in the future going to consider all MUV3 signal associated to a track if it is within 3$\\sigma$\\~1.5 ns to 5$\\sigma$\\~2.5 ns (depending whether we want to include or exclude MUV3 signal, and rounded for clarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c02f098-4856-4f5b-a9d2-22fa6ac1b19a",
   "metadata": {},
   "source": [
    "## Event time\n",
    "As mentioned in the introduction, we have two kind of time for the event:\n",
    " - The event time (timestamp) which represents the NA62 clock cycle (frame) from the beginning of the burst during which the event was acquired\n",
    " - The event fine time which represents the fine time of the trigger within this frame\n",
    "\n",
    "Let's plot these two values, but transforming the event_time from units of frames to units of ns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356183cc-08fe-49b4-b71e-dbfa375ac306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the unit of event_time\n",
    "data[\"event_time_ns\"] = data[\"event_time\"]*constants.clock_period\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "data[\"event_time_ns\"].hist(bins=100, ax=ax[0])\n",
    "ax[0].set_xlabel(\"Event timestamp [ns]\")\n",
    "data[\"ReferenceTime\"].hist(bins=100, ax=ax[1])\n",
    "ax[1].set_xlabel(\"Event finetime [ns]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950bab9-647b-4385-85e3-434276783310",
   "metadata": {},
   "source": [
    "We plot the event finetime naively but this results in a sawtooth profile. This is an artefact due to the fact that the finetime values are coming from digitizing electronics and are therefore already binned. With a naive plotting the digitized values are inconsistently grouped together. Instead if we use a compatible binning (where one is a multiple of the other), we obtain a nice profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc470b4-0990-457a-8d9c-d8d8eaca3c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The binning here is very important to avoid artefacts\n",
    "# Compute the minimum time difference between consecutive fine time values (= electronics bin size)\n",
    "#  - Take unique values/drop duplicate values (not interested in time difference of 0)\n",
    "#  - Sort the values\n",
    "#  - Take the difference between consecutive values\n",
    "#  - Count the various time differences\n",
    "time_diffs = data[\"ReferenceTime\"].drop_duplicates().sort_values().diff().value_counts()\n",
    "# Display -> Same value displayed multiple times. This is a rounding issue, let's just take the first one\n",
    "display(time_diffs)\n",
    "bin_size = time_diffs.index[0]\n",
    "nbins = int(constants.clock_period/bin_size)\n",
    "\n",
    "data[\"ReferenceTime\"].hist(bins=nbins, range=(0, constants.clock_period))\n",
    "plt.xlabel(\"Event finetime [ns]\")\n",
    "plt.title(f\"Event finetime - {nbins} bins of width {constants.clock_period}/{nbins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6220511-0105-4f9d-be57-e5abb150d442",
   "metadata": {},
   "source": [
    "The event time goes from ~1.2 s to ~5.7 s. As mentioned previously this corresponds to a burst. The accelerator complex runs what is called a \"supercycle\" during which the accelerators are filled, the beam accelerated and then extracted to experiments or larger accelerators several times. The destination of the beam from the SPS is different for each extraction and can include the North Area experiments (including NA62 - the beam is split between different targets in that case, each receiving a fraction of the intensity), the LHC, or some specific experiments requiring the whole beam intensity. The supercycle typically lasts between 35 s and 60 s, including one to three extractions to NA62 during the supercycle.\n",
    "\n",
    "Before extracting to NA62, the accelerator complex sends a signal that the beam will be delivered, at which point the NA62 data acquisition electronics is activated. About 1.2 s later, the beam is sent to the experiment for a duration of 4.5 s before stopping. This process is repeated every 15 s to 40 s depending on the SPS supercycle. Each burst is acquired as a separate data file.\n",
    "\n",
    "As written in the introduction, the triggers are generated based on the event time frame and data from 5 time frames are acquired for each event (two time frames surrounding the trigger time frame). Then at analysis level, we have access to a better timing, the finetime. As we discovered above the finetime is given in units of 1/256th of a frame, corresponding to a precision of ~97 ps.\n",
    "\n",
    "In the following, let's have a look at the timing of our objects in the event (tracks and clusters) with respect to the fine time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e95fe-c2ee-442b-b0c1-3d44e62f581d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
